{
 "metadata": {
  "name": "",
  "signature": "sha256:73dec3877226c10ab5caa1c4383ab5a95cd9d08ee316af7321ff1295361613e6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 1, 0.    | spam, non-spam classes\n",
      "\n",
      "# word_freq_make:         continuous.\n",
      "# word_freq_address:      continuous.\n",
      "# word_freq_all:          continuous.\n",
      "# word_freq_3d:           continuous.\n",
      "# word_freq_our:          continuous.\n",
      "# word_freq_over:         continuous.\n",
      "# word_freq_remove:       continuous.\n",
      "# word_freq_internet:     continuous.\n",
      "# word_freq_order:        continuous.\n",
      "# word_freq_mail:         continuous.\n",
      "# word_freq_receive:      continuous.\n",
      "# word_freq_will:         continuous.\n",
      "# word_freq_people:       continuous.\n",
      "# word_freq_report:       continuous.\n",
      "# word_freq_addresses:    continuous.\n",
      "# word_freq_free:         continuous.\n",
      "# word_freq_business:     continuous.\n",
      "# word_freq_email:        continuous.\n",
      "# word_freq_you:          continuous.\n",
      "# word_freq_credit:       continuous.\n",
      "# word_freq_your:         continuous.\n",
      "# word_freq_font:         continuous.\n",
      "# word_freq_000:          continuous.\n",
      "# word_freq_money:        continuous.\n",
      "# word_freq_hp:           continuous.\n",
      "# word_freq_hpl:          continuous.\n",
      "# word_freq_george:       continuous.\n",
      "# word_freq_650:          continuous.\n",
      "# word_freq_lab:          continuous.\n",
      "# word_freq_labs:         continuous.\n",
      "# word_freq_telnet:       continuous.\n",
      "# word_freq_857:          continuous.\n",
      "# word_freq_data:         continuous.\n",
      "# word_freq_415:          continuous.\n",
      "# word_freq_85:           continuous.\n",
      "# word_freq_technology:   continuous.\n",
      "# word_freq_1999:         continuous.\n",
      "# word_freq_parts:        continuous.\n",
      "# word_freq_pm:           continuous.\n",
      "# word_freq_direct:       continuous.\n",
      "# word_freq_cs:           continuous.\n",
      "# word_freq_meeting:      continuous.\n",
      "# word_freq_original:     continuous.\n",
      "# word_freq_project:      continuous.\n",
      "# word_freq_re:           continuous.\n",
      "# word_freq_edu:          continuous.\n",
      "# word_freq_table:        continuous.\n",
      "# word_freq_conference:   continuous.\n",
      "# char_freq_;:            continuous.\n",
      "# char_freq_(:            continuous.\n",
      "# char_freq_[:            continuous.\n",
      "# char_freq_!:            continuous.\n",
      "# char_freq_$:            continuous.\n",
      "# char_freq_#:            continuous.\n",
      "# capital_run_length_average: continuous.\n",
      "# capital_run_length_longest: continuous.\n",
      "# capital_run_length_total:   continuous."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports\n",
      "import pandas as pd\n",
      "import statsmodels.formula.api as smf\n",
      "import statsmodels.api as sm\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from sklearn import linear_model\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn import preprocessing\n",
      "\n",
      "# this allows plots to appear directly in the notebook\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%html \n",
      "<link rel=\"stylesheet\" href=\"http://bit.ly/1DxvcrA\">"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<link rel=\"stylesheet\" href=\"http://bit.ly/1DxvcrA\">"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x10c2d0e10>"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = ['word_freq_make',\n",
      "'word_freq_address',\n",
      "'word_freq_all',\n",
      "'word_freq_3d',\n",
      "'word_freq_our',\n",
      "'word_freq_over',\n",
      "'word_freq_remove',\n",
      "'word_freq_internet',\n",
      "'word_freq_order',\n",
      "'word_freq_mail',\n",
      "'word_freq_receive',\n",
      "'word_freq_will',\n",
      "'word_freq_people',\n",
      "'word_freq_report',\n",
      "'word_freq_addresses',\n",
      "'word_freq_free',\n",
      "'word_freq_business',\n",
      "'word_freq_email',\n",
      "'word_freq_you',\n",
      "'word_freq_credit',\n",
      "'word_freq_your',\n",
      "'word_freq_font',\n",
      "'word_freq_000',\n",
      "'word_freq_money',\n",
      "'word_freq_hp',\n",
      "'word_freq_hpl',\n",
      "'word_freq_george',\n",
      "'word_freq_650',\n",
      "'word_freq_lab',\n",
      "'word_freq_labs',\n",
      "'word_freq_telnet',\n",
      "'word_freq_857',\n",
      "'word_freq_data',\n",
      "'word_freq_415',\n",
      "'word_freq_85',\n",
      "'word_freq_technology',\n",
      "'word_freq_1999',\n",
      "'word_freq_parts',\n",
      "'word_freq_pm',\n",
      "'word_freq_direct',\n",
      "'word_freq_cs',\n",
      "'word_freq_meeting',\n",
      "'word_freq_original',\n",
      "'word_freq_project',\n",
      "'word_freq_re',\n",
      "'word_freq_edu',\n",
      "'word_freq_table',\n",
      "'word_freq_conference',\n",
      "'char_freq_;',\n",
      "'char_freq_(',\n",
      "'char_freq_[',\n",
      "'char_freq_!',\n",
      "'char_freq_$',\n",
      "'char_freq_#',\n",
      "'capital_run_length_average',\n",
      "'capital_run_length_longest',\n",
      "'capital_run_length_total',\n",
      "'is_spam']\n",
      "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
      "data = pd.read_csv(url, names=columns)\n",
      "#data.columns = columns\n",
      "\n",
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word_freq_make</th>\n",
        "      <th>word_freq_address</th>\n",
        "      <th>word_freq_all</th>\n",
        "      <th>word_freq_3d</th>\n",
        "      <th>word_freq_our</th>\n",
        "      <th>word_freq_over</th>\n",
        "      <th>word_freq_remove</th>\n",
        "      <th>word_freq_internet</th>\n",
        "      <th>word_freq_order</th>\n",
        "      <th>word_freq_mail</th>\n",
        "      <th>...</th>\n",
        "      <th>char_freq_;</th>\n",
        "      <th>char_freq_(</th>\n",
        "      <th>char_freq_[</th>\n",
        "      <th>char_freq_!</th>\n",
        "      <th>char_freq_$</th>\n",
        "      <th>char_freq_#</th>\n",
        "      <th>capital_run_length_average</th>\n",
        "      <th>capital_run_length_longest</th>\n",
        "      <th>capital_run_length_total</th>\n",
        "      <th>is_spam</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0.00</td>\n",
        "      <td>0.64</td>\n",
        "      <td>0.64</td>\n",
        "      <td>0</td>\n",
        "      <td>0.32</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>...</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0</td>\n",
        "      <td>0.778</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>3.756</td>\n",
        "      <td>61</td>\n",
        "      <td>278</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>0.21</td>\n",
        "      <td>0.28</td>\n",
        "      <td>0.50</td>\n",
        "      <td>0</td>\n",
        "      <td>0.14</td>\n",
        "      <td>0.28</td>\n",
        "      <td>0.21</td>\n",
        "      <td>0.07</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.94</td>\n",
        "      <td>...</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.132</td>\n",
        "      <td>0</td>\n",
        "      <td>0.372</td>\n",
        "      <td>0.180</td>\n",
        "      <td>0.048</td>\n",
        "      <td>5.114</td>\n",
        "      <td>101</td>\n",
        "      <td>1028</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>0.06</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.71</td>\n",
        "      <td>0</td>\n",
        "      <td>1.23</td>\n",
        "      <td>0.19</td>\n",
        "      <td>0.19</td>\n",
        "      <td>0.12</td>\n",
        "      <td>0.64</td>\n",
        "      <td>0.25</td>\n",
        "      <td>...</td>\n",
        "      <td>0.01</td>\n",
        "      <td>0.143</td>\n",
        "      <td>0</td>\n",
        "      <td>0.276</td>\n",
        "      <td>0.184</td>\n",
        "      <td>0.010</td>\n",
        "      <td>9.821</td>\n",
        "      <td>485</td>\n",
        "      <td>2259</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.31</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.31</td>\n",
        "      <td>0.63</td>\n",
        "      <td>...</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.137</td>\n",
        "      <td>0</td>\n",
        "      <td>0.137</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>3.537</td>\n",
        "      <td>40</td>\n",
        "      <td>191</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.31</td>\n",
        "      <td>0.63</td>\n",
        "      <td>0.31</td>\n",
        "      <td>0.63</td>\n",
        "      <td>...</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.135</td>\n",
        "      <td>0</td>\n",
        "      <td>0.135</td>\n",
        "      <td>0.000</td>\n",
        "      <td>0.000</td>\n",
        "      <td>3.537</td>\n",
        "      <td>40</td>\n",
        "      <td>191</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 58 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 140,
       "text": [
        "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
        "0            0.00               0.64           0.64             0   \n",
        "1            0.21               0.28           0.50             0   \n",
        "2            0.06               0.00           0.71             0   \n",
        "3            0.00               0.00           0.00             0   \n",
        "4            0.00               0.00           0.00             0   \n",
        "\n",
        "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
        "0           0.32            0.00              0.00                0.00   \n",
        "1           0.14            0.28              0.21                0.07   \n",
        "2           1.23            0.19              0.19                0.12   \n",
        "3           0.63            0.00              0.31                0.63   \n",
        "4           0.63            0.00              0.31                0.63   \n",
        "\n",
        "   word_freq_order  word_freq_mail   ...     char_freq_;  char_freq_(  \\\n",
        "0             0.00            0.00   ...            0.00        0.000   \n",
        "1             0.00            0.94   ...            0.00        0.132   \n",
        "2             0.64            0.25   ...            0.01        0.143   \n",
        "3             0.31            0.63   ...            0.00        0.137   \n",
        "4             0.31            0.63   ...            0.00        0.135   \n",
        "\n",
        "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
        "0            0        0.778        0.000        0.000   \n",
        "1            0        0.372        0.180        0.048   \n",
        "2            0        0.276        0.184        0.010   \n",
        "3            0        0.137        0.000        0.000   \n",
        "4            0        0.135        0.000        0.000   \n",
        "\n",
        "   capital_run_length_average  capital_run_length_longest  \\\n",
        "0                       3.756                          61   \n",
        "1                       5.114                         101   \n",
        "2                       9.821                         485   \n",
        "3                       3.537                          40   \n",
        "4                       3.537                          40   \n",
        "\n",
        "   capital_run_length_total  is_spam  \n",
        "0                       278        1  \n",
        "1                      1028        1  \n",
        "2                      2259        1  \n",
        "3                       191        1  \n",
        "4                       191        1  \n",
        "\n",
        "[5 rows x 58 columns]"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word_freq_make</th>\n",
        "      <th>word_freq_address</th>\n",
        "      <th>word_freq_all</th>\n",
        "      <th>word_freq_3d</th>\n",
        "      <th>word_freq_our</th>\n",
        "      <th>word_freq_over</th>\n",
        "      <th>word_freq_remove</th>\n",
        "      <th>word_freq_internet</th>\n",
        "      <th>word_freq_order</th>\n",
        "      <th>word_freq_mail</th>\n",
        "      <th>...</th>\n",
        "      <th>char_freq_;</th>\n",
        "      <th>char_freq_(</th>\n",
        "      <th>char_freq_[</th>\n",
        "      <th>char_freq_!</th>\n",
        "      <th>char_freq_$</th>\n",
        "      <th>char_freq_#</th>\n",
        "      <th>capital_run_length_average</th>\n",
        "      <th>capital_run_length_longest</th>\n",
        "      <th>capital_run_length_total</th>\n",
        "      <th>is_spam</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "      <td>4601.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>0.104553</td>\n",
        "      <td>0.213015</td>\n",
        "      <td>0.280656</td>\n",
        "      <td>0.065425</td>\n",
        "      <td>0.312223</td>\n",
        "      <td>0.095901</td>\n",
        "      <td>0.114208</td>\n",
        "      <td>0.105295</td>\n",
        "      <td>0.090067</td>\n",
        "      <td>0.239413</td>\n",
        "      <td>...</td>\n",
        "      <td>0.038575</td>\n",
        "      <td>0.139030</td>\n",
        "      <td>0.016976</td>\n",
        "      <td>0.269071</td>\n",
        "      <td>0.075811</td>\n",
        "      <td>0.044238</td>\n",
        "      <td>5.191515</td>\n",
        "      <td>52.172789</td>\n",
        "      <td>283.289285</td>\n",
        "      <td>0.394045</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>0.305358</td>\n",
        "      <td>1.290575</td>\n",
        "      <td>0.504143</td>\n",
        "      <td>1.395151</td>\n",
        "      <td>0.672513</td>\n",
        "      <td>0.273824</td>\n",
        "      <td>0.391441</td>\n",
        "      <td>0.401071</td>\n",
        "      <td>0.278616</td>\n",
        "      <td>0.644755</td>\n",
        "      <td>...</td>\n",
        "      <td>0.243471</td>\n",
        "      <td>0.270355</td>\n",
        "      <td>0.109394</td>\n",
        "      <td>0.815672</td>\n",
        "      <td>0.245882</td>\n",
        "      <td>0.429342</td>\n",
        "      <td>31.729449</td>\n",
        "      <td>194.891310</td>\n",
        "      <td>606.347851</td>\n",
        "      <td>0.488698</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>1.588000</td>\n",
        "      <td>6.000000</td>\n",
        "      <td>35.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.065000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>2.276000</td>\n",
        "      <td>15.000000</td>\n",
        "      <td>95.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.420000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.380000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.160000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.188000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.315000</td>\n",
        "      <td>0.052000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>3.706000</td>\n",
        "      <td>43.000000</td>\n",
        "      <td>266.000000</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>4.540000</td>\n",
        "      <td>14.280000</td>\n",
        "      <td>5.100000</td>\n",
        "      <td>42.810000</td>\n",
        "      <td>10.000000</td>\n",
        "      <td>5.880000</td>\n",
        "      <td>7.270000</td>\n",
        "      <td>11.110000</td>\n",
        "      <td>5.260000</td>\n",
        "      <td>18.180000</td>\n",
        "      <td>...</td>\n",
        "      <td>4.385000</td>\n",
        "      <td>9.752000</td>\n",
        "      <td>4.081000</td>\n",
        "      <td>32.478000</td>\n",
        "      <td>6.003000</td>\n",
        "      <td>19.829000</td>\n",
        "      <td>1102.500000</td>\n",
        "      <td>9989.000000</td>\n",
        "      <td>15841.000000</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 58 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
        "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
        "mean         0.104553           0.213015       0.280656      0.065425   \n",
        "std          0.305358           1.290575       0.504143      1.395151   \n",
        "min          0.000000           0.000000       0.000000      0.000000   \n",
        "25%          0.000000           0.000000       0.000000      0.000000   \n",
        "50%          0.000000           0.000000       0.000000      0.000000   \n",
        "75%          0.000000           0.000000       0.420000      0.000000   \n",
        "max          4.540000          14.280000       5.100000     42.810000   \n",
        "\n",
        "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
        "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
        "mean        0.312223        0.095901          0.114208            0.105295   \n",
        "std         0.672513        0.273824          0.391441            0.401071   \n",
        "min         0.000000        0.000000          0.000000            0.000000   \n",
        "25%         0.000000        0.000000          0.000000            0.000000   \n",
        "50%         0.000000        0.000000          0.000000            0.000000   \n",
        "75%         0.380000        0.000000          0.000000            0.000000   \n",
        "max        10.000000        5.880000          7.270000           11.110000   \n",
        "\n",
        "       word_freq_order  word_freq_mail     ...       char_freq_;  char_freq_(  \\\n",
        "count      4601.000000     4601.000000     ...       4601.000000  4601.000000   \n",
        "mean          0.090067        0.239413     ...          0.038575     0.139030   \n",
        "std           0.278616        0.644755     ...          0.243471     0.270355   \n",
        "min           0.000000        0.000000     ...          0.000000     0.000000   \n",
        "25%           0.000000        0.000000     ...          0.000000     0.000000   \n",
        "50%           0.000000        0.000000     ...          0.000000     0.065000   \n",
        "75%           0.000000        0.160000     ...          0.000000     0.188000   \n",
        "max           5.260000       18.180000     ...          4.385000     9.752000   \n",
        "\n",
        "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
        "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
        "mean      0.016976     0.269071     0.075811     0.044238   \n",
        "std       0.109394     0.815672     0.245882     0.429342   \n",
        "min       0.000000     0.000000     0.000000     0.000000   \n",
        "25%       0.000000     0.000000     0.000000     0.000000   \n",
        "50%       0.000000     0.000000     0.000000     0.000000   \n",
        "75%       0.000000     0.315000     0.052000     0.000000   \n",
        "max       4.081000    32.478000     6.003000    19.829000   \n",
        "\n",
        "       capital_run_length_average  capital_run_length_longest  \\\n",
        "count                 4601.000000                 4601.000000   \n",
        "mean                     5.191515                   52.172789   \n",
        "std                     31.729449                  194.891310   \n",
        "min                      1.000000                    1.000000   \n",
        "25%                      1.588000                    6.000000   \n",
        "50%                      2.276000                   15.000000   \n",
        "75%                      3.706000                   43.000000   \n",
        "max                   1102.500000                 9989.000000   \n",
        "\n",
        "       capital_run_length_total      is_spam  \n",
        "count               4601.000000  4601.000000  \n",
        "mean                 283.289285     0.394045  \n",
        "std                  606.347851     0.488698  \n",
        "min                    1.000000     0.000000  \n",
        "25%                   35.000000     0.000000  \n",
        "50%                   95.000000     0.000000  \n",
        "75%                  266.000000     1.000000  \n",
        "max                15841.000000     1.000000  \n",
        "\n",
        "[8 rows x 58 columns]"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#splitting the data into train and test\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "# X = data[['word_freq_make', 'word_freq_address', 'word_freq_all']]\n",
      "# y = data.is_spam\n",
      "\n",
      "# create dataframes with an intercept column\n",
      "y, X = dmatrices(\"is_spam ~ word_freq_make + word_freq_address + word_freq_all + word_freq_3d + word_freq_our + word_freq_over + word_freq_remove + word_freq_internet + word_freq_order + word_freq_mail + word_freq_receive + word_freq_will + word_freq_people + word_freq_report + word_freq_addresses + word_freq_free + word_freq_business + word_freq_email + word_freq_you + word_freq_credit + word_freq_your + word_freq_font + word_freq_000 + word_freq_money + word_freq_hp + word_freq_hpl + word_freq_george + word_freq_650 + word_freq_lab + word_freq_labs + word_freq_telnet + word_freq_857 + word_freq_data + word_freq_415 + word_freq_85 + word_freq_technology + word_freq_1999 + word_freq_parts + word_freq_pm + word_freq_direct + word_freq_cs + word_freq_meeting + word_freq_original + word_freq_project + word_freq_re + word_freq_edu + word_freq_table + word_freq_conference + capital_run_length_average + capital_run_length_longest + capital_run_length_total\", lm_spam, return_type=\"dataframe\")\n",
      "\n",
      "# confirm columns and target\n",
      "print X.columns\n",
      "print y.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'Intercept', u'word_freq_make', u'word_freq_address', u'word_freq_all', u'word_freq_3d', u'word_freq_our', u'word_freq_over', u'word_freq_remove', u'word_freq_internet', u'word_freq_order', u'word_freq_mail', u'word_freq_receive', u'word_freq_will', u'word_freq_people', u'word_freq_report', u'word_freq_addresses', u'word_freq_free', u'word_freq_business', u'word_freq_email', u'word_freq_you', u'word_freq_credit', u'word_freq_your', u'word_freq_font', u'word_freq_000', u'word_freq_money', u'word_freq_hp', u'word_freq_hpl', u'word_freq_george', u'word_freq_650', u'word_freq_lab', u'word_freq_labs', u'word_freq_telnet', u'word_freq_857', u'word_freq_data', u'word_freq_415', u'word_freq_85', u'word_freq_technology', u'word_freq_1999', u'word_freq_parts', u'word_freq_pm', u'word_freq_direct', u'word_freq_cs', u'word_freq_meeting', u'word_freq_original', u'word_freq_project', u'word_freq_re', u'word_freq_edu', u'word_freq_table', u'word_freq_conference', u'capital_run_length_average', u'capital_run_length_longest', u'capital_run_length_total'], dtype='object')\n",
        "   is_spam\n",
        "2        1\n",
        "3        1\n",
        "4        1\n",
        "5        1\n",
        "6        1\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# flatten y into a 1-D array\n",
      "y = np.ravel(y)\n",
      "# make logistic regression model, and fit with X and y\n",
      "model = LogisticRegression()\n",
      "model = model.fit(X, y)\n",
      "\n",
      "# check accuracy on the training set\n",
      "model.score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "0.92063492063492058"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# what percent is spam?\n",
      "y.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 144,
       "text": [
        "0.3937812567949554"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine the coefficients\n",
      "pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>Intercept</td>\n",
        "      <td>[-0.681552398034]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>word_freq_make</td>\n",
        "      <td>[-0.243707199669]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>word_freq_address</td>\n",
        "      <td>[-0.161044098461]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>word_freq_all</td>\n",
        "      <td>[0.143534197773]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>word_freq_3d</td>\n",
        "      <td>[0.902779896695]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>word_freq_our</td>\n",
        "      <td>[0.52277661307]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>word_freq_over</td>\n",
        "      <td>[0.937934321705]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>word_freq_remove</td>\n",
        "      <td>[2.36376799225]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>word_freq_internet</td>\n",
        "      <td>[0.684357950444]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>word_freq_order</td>\n",
        "      <td>[0.868445756556]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>word_freq_mail</td>\n",
        "      <td>[0.0900347605821]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>word_freq_receive</td>\n",
        "      <td>[-0.301471073339]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>word_freq_will</td>\n",
        "      <td>[-0.145009500985]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>word_freq_people</td>\n",
        "      <td>[0.201138606776]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>word_freq_report</td>\n",
        "      <td>[0.158005639191]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>word_freq_addresses</td>\n",
        "      <td>[0.865582613077]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>word_freq_free</td>\n",
        "      <td>[1.12888774769]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>word_freq_business</td>\n",
        "      <td>[0.868156522146]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>word_freq_email</td>\n",
        "      <td>[0.1611552979]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>word_freq_you</td>\n",
        "      <td>[0.0803201949175]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>word_freq_credit</td>\n",
        "      <td>[1.15685284948]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>word_freq_your</td>\n",
        "      <td>[0.247594745825]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>word_freq_font</td>\n",
        "      <td>[0.0730793103339]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>word_freq_000</td>\n",
        "      <td>[2.47356238239]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>word_freq_money</td>\n",
        "      <td>[0.707067550338]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>word_freq_hp</td>\n",
        "      <td>[-1.88990884232]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>word_freq_hpl</td>\n",
        "      <td>[-1.16541524336]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>word_freq_george</td>\n",
        "      <td>[-4.14424578103]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>word_freq_650</td>\n",
        "      <td>[0.332775103546]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>word_freq_lab</td>\n",
        "      <td>[-1.45428381192]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>word_freq_labs</td>\n",
        "      <td>[-0.428352903105]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td>word_freq_telnet</td>\n",
        "      <td>[-0.561278249069]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td>word_freq_857</td>\n",
        "      <td>[-0.0172384708346]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td>word_freq_data</td>\n",
        "      <td>[-1.04249804936]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td>word_freq_415</td>\n",
        "      <td>[0.259422209348]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td>word_freq_85</td>\n",
        "      <td>[-0.856156033649]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td>word_freq_technology</td>\n",
        "      <td>[0.918237616492]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td>word_freq_1999</td>\n",
        "      <td>[-0.0333966200144]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td>word_freq_parts</td>\n",
        "      <td>[-0.559051172871]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td>word_freq_pm</td>\n",
        "      <td>[-0.930822995623]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td>word_freq_direct</td>\n",
        "      <td>[-0.317526239634]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td>word_freq_cs</td>\n",
        "      <td>[-1.77575575947]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td>word_freq_meeting</td>\n",
        "      <td>[-1.96664536092]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td>word_freq_original</td>\n",
        "      <td>[-0.942712287929]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td>word_freq_project</td>\n",
        "      <td>[-1.47866444948]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td>word_freq_re</td>\n",
        "      <td>[-0.479007015117]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td>word_freq_edu</td>\n",
        "      <td>[-1.56947077824]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td>word_freq_table</td>\n",
        "      <td>[-1.15648306101]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td>word_freq_conference</td>\n",
        "      <td>[-1.81602429005]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td>capital_run_length_average</td>\n",
        "      <td>[-0.00620549919124]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50</th>\n",
        "      <td>capital_run_length_longest</td>\n",
        "      <td>[0.00970805255018]</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>51</th>\n",
        "      <td>capital_run_length_total</td>\n",
        "      <td>[0.000584728214867]</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 145,
       "text": [
        "                             0                    1\n",
        "0                    Intercept    [-0.681552398034]\n",
        "1               word_freq_make    [-0.243707199669]\n",
        "2            word_freq_address    [-0.161044098461]\n",
        "3                word_freq_all     [0.143534197773]\n",
        "4                 word_freq_3d     [0.902779896695]\n",
        "5                word_freq_our      [0.52277661307]\n",
        "6               word_freq_over     [0.937934321705]\n",
        "7             word_freq_remove      [2.36376799225]\n",
        "8           word_freq_internet     [0.684357950444]\n",
        "9              word_freq_order     [0.868445756556]\n",
        "10              word_freq_mail    [0.0900347605821]\n",
        "11           word_freq_receive    [-0.301471073339]\n",
        "12              word_freq_will    [-0.145009500985]\n",
        "13            word_freq_people     [0.201138606776]\n",
        "14            word_freq_report     [0.158005639191]\n",
        "15         word_freq_addresses     [0.865582613077]\n",
        "16              word_freq_free      [1.12888774769]\n",
        "17          word_freq_business     [0.868156522146]\n",
        "18             word_freq_email       [0.1611552979]\n",
        "19               word_freq_you    [0.0803201949175]\n",
        "20            word_freq_credit      [1.15685284948]\n",
        "21              word_freq_your     [0.247594745825]\n",
        "22              word_freq_font    [0.0730793103339]\n",
        "23               word_freq_000      [2.47356238239]\n",
        "24             word_freq_money     [0.707067550338]\n",
        "25                word_freq_hp     [-1.88990884232]\n",
        "26               word_freq_hpl     [-1.16541524336]\n",
        "27            word_freq_george     [-4.14424578103]\n",
        "28               word_freq_650     [0.332775103546]\n",
        "29               word_freq_lab     [-1.45428381192]\n",
        "30              word_freq_labs    [-0.428352903105]\n",
        "31            word_freq_telnet    [-0.561278249069]\n",
        "32               word_freq_857   [-0.0172384708346]\n",
        "33              word_freq_data     [-1.04249804936]\n",
        "34               word_freq_415     [0.259422209348]\n",
        "35                word_freq_85    [-0.856156033649]\n",
        "36        word_freq_technology     [0.918237616492]\n",
        "37              word_freq_1999   [-0.0333966200144]\n",
        "38             word_freq_parts    [-0.559051172871]\n",
        "39                word_freq_pm    [-0.930822995623]\n",
        "40            word_freq_direct    [-0.317526239634]\n",
        "41                word_freq_cs     [-1.77575575947]\n",
        "42           word_freq_meeting     [-1.96664536092]\n",
        "43          word_freq_original    [-0.942712287929]\n",
        "44           word_freq_project     [-1.47866444948]\n",
        "45                word_freq_re    [-0.479007015117]\n",
        "46               word_freq_edu     [-1.56947077824]\n",
        "47             word_freq_table     [-1.15648306101]\n",
        "48        word_freq_conference     [-1.81602429005]\n",
        "49  capital_run_length_average  [-0.00620549919124]\n",
        "50  capital_run_length_longest   [0.00970805255018]\n",
        "51    capital_run_length_total  [0.000584728214867]"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# evaluate the model\n",
      "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
      "\n",
      "# train = pd.DataFrame(data=X_train, columns=['word_freq_make', 'word_freq_address', 'word_freq_all'])\n",
      "# train['is_spam'] = y_train\n",
      "\n",
      "# test = pd.DataFrame(data=X_test, columns=['word_freq_make', 'word_freq_address', 'word_freq_all'])\n",
      "# test['is_spam'] = y_test\n",
      "# evaluate the model by splitting into train and test sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \\\n",
      "                                                    random_state=12)\n",
      "model2 = LogisticRegression()\n",
      "model2.fit(X_train, y_train)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 146,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict class labels for the test set\n",
      "predicted = model2.predict(X_test)\n",
      "print predicted"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.  1.  0. ...,  0.  0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate class probabilities\n",
      "probs = model2.predict_proba(X_test)\n",
      "print probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  2.73534283e-01   7.26465717e-01]\n",
        " [  1.44888808e-03   9.98551112e-01]\n",
        " [  7.31682589e-01   2.68317411e-01]\n",
        " ..., \n",
        " [  5.75613797e-01   4.24386203e-01]\n",
        " [  6.24323547e-01   3.75676453e-01]\n",
        " [  9.99904582e-01   9.54175001e-05]]\n"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate evaluation metrics\n",
      "print metrics.accuracy_score(y_test, predicted)\n",
      "#area under curve\n",
      "print metrics.roc_auc_score(y_test, probs[:, 1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.910869565217\n",
        "0.960710665553\n"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# confusion matrix\n",
      "print metrics.confusion_matrix(y_test, predicted)\n",
      "print metrics.classification_report(y_test, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[799  56]\n",
        " [ 67 458]]\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.92      0.93      0.93       855\n",
        "        1.0       0.89      0.87      0.88       525\n",
        "\n",
        "avg / total       0.91      0.91      0.91      1380\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# evaluate the model using 10-fold cross-validation\n",
      "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
      "print scores\n",
      "print scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.92190889  0.92608696  0.89782609  0.93913043  0.92391304  0.92173913\n",
        "  0.94782609  0.91956522  0.83877996  0.85185185]\n",
        "0.908862765851\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est = sm.OLS(y, X).fit()\n",
      "est.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.530</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.524</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   100.4</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Tue, 28 Apr 2015</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>20:57:17</td>     <th>  Log-Likelihood:    </th> <td> -1497.4</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>  4599</td>      <th>  AIC:               </th> <td>   3099.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>  4547</td>      <th>  BIC:               </th> <td>   3433.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>    51</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th>                  <td>    0.1984</td> <td>    0.011</td> <td>   17.670</td> <td> 0.000</td> <td>    0.176     0.220</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_make</th>             <td>   -0.0402</td> <td>    0.017</td> <td>   -2.318</td> <td> 0.020</td> <td>   -0.074    -0.006</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_address</th>          <td>   -0.0116</td> <td>    0.004</td> <td>   -2.973</td> <td> 0.003</td> <td>   -0.019    -0.004</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_all</th>              <td>    0.0481</td> <td>    0.010</td> <td>    4.643</td> <td> 0.000</td> <td>    0.028     0.068</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_3d</th>               <td>    0.0123</td> <td>    0.004</td> <td>    3.449</td> <td> 0.001</td> <td>    0.005     0.019</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_our</th>              <td>    0.0831</td> <td>    0.008</td> <td>   10.632</td> <td> 0.000</td> <td>    0.068     0.098</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_over</th>             <td>    0.1282</td> <td>    0.019</td> <td>    6.738</td> <td> 0.000</td> <td>    0.091     0.165</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_remove</th>           <td>    0.2228</td> <td>    0.013</td> <td>   16.586</td> <td> 0.000</td> <td>    0.196     0.249</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_internet</th>         <td>    0.0959</td> <td>    0.013</td> <td>    7.386</td> <td> 0.000</td> <td>    0.070     0.121</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_order</th>            <td>    0.0871</td> <td>    0.020</td> <td>    4.459</td> <td> 0.000</td> <td>    0.049     0.125</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_mail</th>             <td>    0.0170</td> <td>    0.008</td> <td>    2.124</td> <td> 0.034</td> <td>    0.001     0.033</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_receive</th>          <td>    0.0427</td> <td>    0.027</td> <td>    1.578</td> <td> 0.115</td> <td>   -0.010     0.096</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_will</th>             <td>   -0.0276</td> <td>    0.006</td> <td>   -4.535</td> <td> 0.000</td> <td>   -0.040    -0.016</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_people</th>           <td>    0.0446</td> <td>    0.017</td> <td>    2.625</td> <td> 0.009</td> <td>    0.011     0.078</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_report</th>           <td>    0.0090</td> <td>    0.015</td> <td>    0.589</td> <td> 0.556</td> <td>   -0.021     0.039</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_addresses</th>        <td>    0.0084</td> <td>    0.023</td> <td>    0.372</td> <td> 0.710</td> <td>   -0.036     0.053</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_free</th>             <td>    0.0824</td> <td>    0.006</td> <td>   13.300</td> <td> 0.000</td> <td>    0.070     0.095</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_business</th>         <td>    0.0600</td> <td>    0.012</td> <td>    4.900</td> <td> 0.000</td> <td>    0.036     0.084</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_email</th>            <td>    0.0585</td> <td>    0.010</td> <td>    5.797</td> <td> 0.000</td> <td>    0.039     0.078</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_you</th>              <td>    0.0179</td> <td>    0.003</td> <td>    5.623</td> <td> 0.000</td> <td>    0.012     0.024</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_credit</th>           <td>    0.0656</td> <td>    0.010</td> <td>    6.463</td> <td> 0.000</td> <td>    0.046     0.086</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_your</th>             <td>    0.0565</td> <td>    0.005</td> <td>   11.764</td> <td> 0.000</td> <td>    0.047     0.066</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_font</th>             <td>    0.0323</td> <td>    0.005</td> <td>    6.565</td> <td> 0.000</td> <td>    0.023     0.042</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_000</th>              <td>    0.2232</td> <td>    0.016</td> <td>   13.998</td> <td> 0.000</td> <td>    0.192     0.254</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_money</th>            <td>    0.0969</td> <td>    0.012</td> <td>    8.213</td> <td> 0.000</td> <td>    0.074     0.120</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_hp</th>               <td>   -0.0253</td> <td>    0.004</td> <td>   -6.717</td> <td> 0.000</td> <td>   -0.033    -0.018</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_hpl</th>              <td>   -0.0237</td> <td>    0.007</td> <td>   -3.418</td> <td> 0.001</td> <td>   -0.037    -0.010</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_george</th>           <td>   -0.0126</td> <td>    0.002</td> <td>   -8.098</td> <td> 0.000</td> <td>   -0.016    -0.010</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_650</th>              <td>   -0.0044</td> <td>    0.013</td> <td>   -0.340</td> <td> 0.734</td> <td>   -0.029     0.021</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_lab</th>              <td>   -0.0076</td> <td>    0.012</td> <td>   -0.654</td> <td> 0.513</td> <td>   -0.030     0.015</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_labs</th>             <td>   -0.0480</td> <td>    0.016</td> <td>   -2.909</td> <td> 0.004</td> <td>   -0.080    -0.016</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_telnet</th>           <td>   -0.0223</td> <td>    0.020</td> <td>   -1.114</td> <td> 0.265</td> <td>   -0.062     0.017</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_857</th>              <td>   -0.1322</td> <td>    0.174</td> <td>   -0.760</td> <td> 0.447</td> <td>   -0.473     0.209</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_data</th>             <td>   -0.0472</td> <td>    0.009</td> <td>   -5.194</td> <td> 0.000</td> <td>   -0.065    -0.029</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_415</th>              <td>    0.1753</td> <td>    0.171</td> <td>    1.023</td> <td> 0.306</td> <td>   -0.161     0.511</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_85</th>               <td>   -0.0295</td> <td>    0.013</td> <td>   -2.343</td> <td> 0.019</td> <td>   -0.054    -0.005</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_technology</th>       <td>    0.0272</td> <td>    0.020</td> <td>    1.344</td> <td> 0.179</td> <td>   -0.012     0.067</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_1999</th>             <td>   -0.0426</td> <td>    0.013</td> <td>   -3.258</td> <td> 0.001</td> <td>   -0.068    -0.017</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_parts</th>            <td>   -0.0576</td> <td>    0.023</td> <td>   -2.481</td> <td> 0.013</td> <td>   -0.103    -0.012</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_pm</th>               <td>   -0.0267</td> <td>    0.012</td> <td>   -2.216</td> <td> 0.027</td> <td>   -0.050    -0.003</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_direct</th>           <td>    0.0439</td> <td>    0.028</td> <td>    1.561</td> <td> 0.119</td> <td>   -0.011     0.099</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_cs</th>               <td>   -0.0155</td> <td>    0.015</td> <td>   -1.048</td> <td> 0.295</td> <td>   -0.045     0.014</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_meeting</th>          <td>   -0.0373</td> <td>    0.008</td> <td>   -4.748</td> <td> 0.000</td> <td>   -0.053    -0.022</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_original</th>         <td>   -0.0744</td> <td>    0.024</td> <td>   -3.072</td> <td> 0.002</td> <td>   -0.122    -0.027</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_project</th>          <td>   -0.0337</td> <td>    0.008</td> <td>   -4.145</td> <td> 0.000</td> <td>   -0.050    -0.018</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_re</th>               <td>   -0.0303</td> <td>    0.005</td> <td>   -5.937</td> <td> 0.000</td> <td>   -0.040    -0.020</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_edu</th>              <td>   -0.0395</td> <td>    0.006</td> <td>   -6.626</td> <td> 0.000</td> <td>   -0.051    -0.028</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_table</th>            <td>   -0.2175</td> <td>    0.066</td> <td>   -3.319</td> <td> 0.001</td> <td>   -0.346    -0.089</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>word_freq_conference</th>       <td>   -0.0613</td> <td>    0.018</td> <td>   -3.498</td> <td> 0.000</td> <td>   -0.096    -0.027</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>capital_run_length_average</th> <td>    0.0004</td> <td>    0.000</td> <td>    2.257</td> <td> 0.024</td> <td> 5.46e-05     0.001</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>capital_run_length_longest</th> <td> 5.284e-05</td> <td> 3.38e-05</td> <td>    1.561</td> <td> 0.118</td> <td>-1.35e-05     0.000</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>capital_run_length_total</th>   <td> 8.826e-05</td> <td> 9.93e-06</td> <td>    8.890</td> <td> 0.000</td> <td> 6.88e-05     0.000</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>57.236</td> <th>  Durbin-Watson:     </th> <td>   0.942</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  59.077</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 0.274</td> <th>  Prob(JB):          </th> <td>1.48e-13</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 3.093</td> <th>  Cond. No.          </th> <td>3.32e+04</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.530\n",
        "Model:                            OLS   Adj. R-squared:                  0.524\n",
        "Method:                 Least Squares   F-statistic:                     100.4\n",
        "Date:                Tue, 28 Apr 2015   Prob (F-statistic):               0.00\n",
        "Time:                        20:57:17   Log-Likelihood:                -1497.4\n",
        "No. Observations:                4599   AIC:                             3099.\n",
        "Df Residuals:                    4547   BIC:                             3433.\n",
        "Df Model:                          51                                         \n",
        "==============================================================================================\n",
        "                                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "----------------------------------------------------------------------------------------------\n",
        "Intercept                      0.1984      0.011     17.670      0.000         0.176     0.220\n",
        "word_freq_make                -0.0402      0.017     -2.318      0.020        -0.074    -0.006\n",
        "word_freq_address             -0.0116      0.004     -2.973      0.003        -0.019    -0.004\n",
        "word_freq_all                  0.0481      0.010      4.643      0.000         0.028     0.068\n",
        "word_freq_3d                   0.0123      0.004      3.449      0.001         0.005     0.019\n",
        "word_freq_our                  0.0831      0.008     10.632      0.000         0.068     0.098\n",
        "word_freq_over                 0.1282      0.019      6.738      0.000         0.091     0.165\n",
        "word_freq_remove               0.2228      0.013     16.586      0.000         0.196     0.249\n",
        "word_freq_internet             0.0959      0.013      7.386      0.000         0.070     0.121\n",
        "word_freq_order                0.0871      0.020      4.459      0.000         0.049     0.125\n",
        "word_freq_mail                 0.0170      0.008      2.124      0.034         0.001     0.033\n",
        "word_freq_receive              0.0427      0.027      1.578      0.115        -0.010     0.096\n",
        "word_freq_will                -0.0276      0.006     -4.535      0.000        -0.040    -0.016\n",
        "word_freq_people               0.0446      0.017      2.625      0.009         0.011     0.078\n",
        "word_freq_report               0.0090      0.015      0.589      0.556        -0.021     0.039\n",
        "word_freq_addresses            0.0084      0.023      0.372      0.710        -0.036     0.053\n",
        "word_freq_free                 0.0824      0.006     13.300      0.000         0.070     0.095\n",
        "word_freq_business             0.0600      0.012      4.900      0.000         0.036     0.084\n",
        "word_freq_email                0.0585      0.010      5.797      0.000         0.039     0.078\n",
        "word_freq_you                  0.0179      0.003      5.623      0.000         0.012     0.024\n",
        "word_freq_credit               0.0656      0.010      6.463      0.000         0.046     0.086\n",
        "word_freq_your                 0.0565      0.005     11.764      0.000         0.047     0.066\n",
        "word_freq_font                 0.0323      0.005      6.565      0.000         0.023     0.042\n",
        "word_freq_000                  0.2232      0.016     13.998      0.000         0.192     0.254\n",
        "word_freq_money                0.0969      0.012      8.213      0.000         0.074     0.120\n",
        "word_freq_hp                  -0.0253      0.004     -6.717      0.000        -0.033    -0.018\n",
        "word_freq_hpl                 -0.0237      0.007     -3.418      0.001        -0.037    -0.010\n",
        "word_freq_george              -0.0126      0.002     -8.098      0.000        -0.016    -0.010\n",
        "word_freq_650                 -0.0044      0.013     -0.340      0.734        -0.029     0.021\n",
        "word_freq_lab                 -0.0076      0.012     -0.654      0.513        -0.030     0.015\n",
        "word_freq_labs                -0.0480      0.016     -2.909      0.004        -0.080    -0.016\n",
        "word_freq_telnet              -0.0223      0.020     -1.114      0.265        -0.062     0.017\n",
        "word_freq_857                 -0.1322      0.174     -0.760      0.447        -0.473     0.209\n",
        "word_freq_data                -0.0472      0.009     -5.194      0.000        -0.065    -0.029\n",
        "word_freq_415                  0.1753      0.171      1.023      0.306        -0.161     0.511\n",
        "word_freq_85                  -0.0295      0.013     -2.343      0.019        -0.054    -0.005\n",
        "word_freq_technology           0.0272      0.020      1.344      0.179        -0.012     0.067\n",
        "word_freq_1999                -0.0426      0.013     -3.258      0.001        -0.068    -0.017\n",
        "word_freq_parts               -0.0576      0.023     -2.481      0.013        -0.103    -0.012\n",
        "word_freq_pm                  -0.0267      0.012     -2.216      0.027        -0.050    -0.003\n",
        "word_freq_direct               0.0439      0.028      1.561      0.119        -0.011     0.099\n",
        "word_freq_cs                  -0.0155      0.015     -1.048      0.295        -0.045     0.014\n",
        "word_freq_meeting             -0.0373      0.008     -4.748      0.000        -0.053    -0.022\n",
        "word_freq_original            -0.0744      0.024     -3.072      0.002        -0.122    -0.027\n",
        "word_freq_project             -0.0337      0.008     -4.145      0.000        -0.050    -0.018\n",
        "word_freq_re                  -0.0303      0.005     -5.937      0.000        -0.040    -0.020\n",
        "word_freq_edu                 -0.0395      0.006     -6.626      0.000        -0.051    -0.028\n",
        "word_freq_table               -0.2175      0.066     -3.319      0.001        -0.346    -0.089\n",
        "word_freq_conference          -0.0613      0.018     -3.498      0.000        -0.096    -0.027\n",
        "capital_run_length_average     0.0004      0.000      2.257      0.024      5.46e-05     0.001\n",
        "capital_run_length_longest  5.284e-05   3.38e-05      1.561      0.118     -1.35e-05     0.000\n",
        "capital_run_length_total    8.826e-05   9.93e-06      8.890      0.000      6.88e-05     0.000\n",
        "==============================================================================\n",
        "Omnibus:                       57.236   Durbin-Watson:                   0.942\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               59.077\n",
        "Skew:                           0.274   Prob(JB):                     1.48e-13\n",
        "Kurtosis:                       3.093   Cond. No.                     3.32e+04\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] The condition number is large, 3.32e+04. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## WIP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from patsy import dmatrices\n",
      "\n",
      "# drop ratings column from data for collinearity\n",
      "lm_spam = data.drop(['is_spam'])\n",
      "lm_spam.head()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "labels ['is_spam'] not contained in axis",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-151-96e2c8615ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# drop ratings column from data for collinearity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlm_spam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_spam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlm_spam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/wnichols/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace)\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/wnichols/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels %s not contained in axis'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: labels ['is_spam'] not contained in axis"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create dataframes with an intercept column\n",
      "y, X = dmatrices(\"is_spam ~ word_freq_make + word_freq_address + word_freq_all + word_freq_3d + word_freq_our + word_freq_over + word_freq_remove + word_freq_internet + word_freq_order + word_freq_mail + word_freq_receive + word_freq_will + word_freq_people + word_freq_report + word_freq_addresses + word_freq_free + word_freq_business + word_freq_email + word_freq_you + word_freq_credit + word_freq_your + word_freq_font + word_freq_000 + word_freq_money + word_freq_hp + word_freq_hpl + word_freq_george + word_freq_650 + word_freq_lab + word_freq_labs + word_freq_telnet + word_freq_857 + word_freq_data + word_freq_415 + word_freq_85 + word_freq_technology + word_freq_1999 + word_freq_parts + word_freq_pm + word_freq_direct + word_freq_cs + word_freq_meeting + word_freq_original + word_freq_project + word_freq_re + word_freq_edu + word_freq_table + word_freq_conference + capital_run_length_average + capital_run_length_longest + capital_run_length_total\", lm_spam, return_type=\"dataframe\")\n",
      "\n",
      "# confirm columns and target\n",
      "print X.columns\n",
      "print y.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}